# A 3D Coarse-to-Fine Framework for Volumetric Medical Image Segmentation

本文提出了一种用于分割胰腺的深度学习网络框架，这个框架的特点是由粗到细，并且不仅适用于正常的胰腺分割，还可以分割病变的异常胰腺。

目前的困难有以下三点：
1. 整个腹部CT中胰腺的尺寸很小
2. 胰腺的纹理、位置、形状和大小十分多样
3. 异常的胰腺，如胰腺囊肿可能会很大程度改变胰腺的样子

本框架的大体思想是首先对图像进行粗略地分割得到胰腺的大致位置，接下来继续对这个大致位置进行更加细致的分割，使分割的结果更加精确。

> 本文采用 3D 神经网络进行器官的分割，相比于传统的 2D FCN 对 CT 进行逐片的分割，3D FCN 更能捕获一些 3D 上下文，这对于辨别背景区域和胰腺器官是非常重要的
>
> 由于 3D 深度神经网络的训练需要更多的内存，但是 GPU 的内存大小有限，无法将整个 CT 扫描的 3D 立方体输入小的子立方体训练 3D FCN 并以滑动窗口方式测试它们

## 大致流程

### 训练阶段

- 从整个 CT 立方体中采样，用子立方体训练 3D FCN，充分利用整个 3D 上下文获得胰腺的粗略位置
- 从 ground truth 获得真实的胰腺位置的子立方体，用部分训练 3D FCN，以达到细化分割的目的

### 测试阶段

- 首先用滑动窗口的方法将粗糙模型应用在整个 CT 立方体上，提取胰腺最有可能的位置。因为在此步骤中我们只需要目标胰腺的粗略位置，因此重叠尺寸可以设置得较小
- 用滑动窗口的方式将精细模型应用于上一步找到的粗略的胰腺器官位置，设置较大的重叠尺寸来获得更加精细的模型

首先规定一下文章中使用的符号

1. 通用的分割模型
   $$M:P=f(X;\Theta)$$
   > 其中：
   >
   > $X$: 表示 3D CT 图像，它与 ground truth 的像素值一一对应；
   >
   > $\Theta$: 表示模型的参数, $\Theta=\{W,B\}$
   >
   > $W=\{W^1,W^2,...,W^L\}$是一组权重
   >
   > $B=\{B^1,B^2,...,B^L\}$表示一组偏差
   >
   > $P$: 表示二进制的预测结果

假设$p(y|x_i;\Theta)$表示最后一层输出的预测体素$x_i$为标签类的概率，则负对数似然损失为
$$L = L(X;\Theta)= -\sum_{x_i\in X} log(p(y_i\lvert x_i;\Theta))$$
通过阈值化$p(y_i\lvert x_i;\Theta)$，我们可以得到二元分割mask $p$

本文还为网络添加了一些辅助层，在网络前向传播的过程中产生侧输出（side outputs）。这些辅助分支形成分支网络，可以使网络在较低层进行特征学习。每个分支共享主干网络的前$d$层权重，由$\Theta_d=\{W_d,B_d\}$表示。除了共享权重外，辅助分支还拥有自己的权重$\hat{\Theta}_d$

辅助分支的损失函数为：
$$L_d(X;\Theta_d,\hat{\Theta}_d)=\sum_{x_i \in X}-log(p(y_i\lvert x_i; \Theta_d, \hat{\Theta}_d))$$

总体的损失函数为：
$$L_{overall} = L+ \sum_{d \in D} \xi_{d}L_{d} + \lambda (\lVert\Theta\lVert^{2}+\sum_{d \in D}\lVert\hat{\Theta_{d}}\lVert^{2})$$

>其中$D$表示一组分支网络，$\xi_{d}$为每个分支网络的重要性，$\lambda (\lVert\Theta\lVert^{2}+\sum_{d \in D}\lVert\hat{\Theta_{d}}\lVert^{2})$为正则化项

## 网络结构
粗分割模型（ResDSN coarse）：
$$M^{C}:P_{C}=f^{C}(X^{C};\Theta^{C})$$
该阶段的目标是从复杂上下文中获得胰腺的粗略分割图$P^{C}$。

网络的输入是重叠尺寸较小的滑动窗口形成的小立方体，经过粗略的分割，我们可以将预测为非胰腺区域的部分去除，这样可以减小上下文的复杂程度，使上下文更简单，更容易进行进一步地分割。

coarse 阶段使用滑动窗口进行输入，因为输出数据为3D的数据立方体，因此维度众多，硬件无法支持将完整的3D立方体作为输入数据，采用滑动窗口的方式可以使输入数据的维度降低，这样不仅可以提高网络计算速度，还能增加准确性（完整的3D CT图像数据含有大量的假阴性）。
基于这个粗略的分结果，我们可以从原图像中剪裁出胰腺区域，为了怎样一下假阴性，我们在该区域的边缘增加了c尺寸为m的扩充。
$$X^{F}=Crop[X^{C}\otimes P^{C};P^{C},m]$$

> + 其中$\otimes$表示对应位置的元素相乘
> + $Crop[X;P,m]$表示从X中剪裁出P的所有体素值为1的区域
> + m为扩充边，在实验中凭经验确定，用于在精细分割阶段更好地分割胰腺的边界体素

![image](./NET(1).png)

如图所示，前3个block为coarse阶段，可以看出粗分割得到了胰腺的大概区域，通过阈值化获得0，1分割图，然后在原图中剪裁出这一部分，在向外扩充一些作为下一阶段的原始输入。

## Fine阶段
这一阶段的主要目的是细化前一阶段的粗分割结果。

网络结构的第4个block为此阶段。这部分依然使用3D FCN作为网络的基础，通过重叠尺寸更大的滑动窗口达到精细分割的目的。输入的依旧是滑动窗口得到的子立方体。

## Coarse-to-Fine Segmentation

将精细分割的结构重新填回粗分割的结构中，如网络结构图的左右一部分所示，用$P^{C2F}$来替换$P^{C}$中的对应元素。

本网络收到3D U-Net，V-Net和VoxResNet的启发，包含了编码器路径和解码器路径两部分。
![image](./NET(2).png)

左侧的编码器部分有多个block，具有不同的分辨率。每个block由一到两个卷积组成，其中每个卷积的卷积核的尺寸为3×3×3,接着是BN,最后是ReLU。block后跟着池化层Pooling，其中Pooling为max-pooling,核的大小为2×2×2，步长为2，通过降低分辨率使卷积核能够获得更大的感受野，学习到更紧凑的特征。在计算资源有限的条件下，使用更小的尺寸可以增加通道的数量，获得更多的特征。

右侧的解码器部分童谣由多个block组成，每个block包含两个卷积，每个卷积后跟一个BN和ReLU，然后连接一个卷积大小为4×4×4，步长为2的反卷积，用来扩大特征图尺寸。由于增大了特征图尺寸，需要将通道数降低（减半）来适应有限的计算资源。

除此之外，与U-Net相同，本网络还建立了一个残差连接用来连接底层和高层的特征图。在前向传播阶段，由网络特征提取阶段（编码器路径）的底层特征图被直接添加到解码器路径的高层特征图中，用来精细化分割，防止细节在卷积核池化的过程中被忽略掉。这种结构还有好处就是在梯度的反向传播过程中梯度的直接相关可以防止出现梯度消失的情况。

## 辅助监督
主干网络的损失函数是由“Res / Conv1b”计算得到的。这一层的输出尺寸与网络的输入尺寸相同，使用1×1×1的卷积核进行卷积，将通道数变为2，得到2个分类，最后通过ground truth计算损失。

辅助网络的损失由“Conv2b”和“Conv3b”产生，由于此时的特征图的尺寸与输入的尺寸不同，需要对该特征图进行反卷积，得到与输入尺寸相同的特征图，然后计算损失。
两个辅助分支的权重设为$\xi_{1}=0.2, \xi_{2}=0.4$

整个网络的损失用之前的公式计算

## 实现细节
### 数据预处理
将原始的CT图像的CT值截断为[-100,240]，然后将CT值标准化为均值为0，方差为1（这个方法值得借鉴），这样计算出的灰度直方图应该会更加均匀。[-100,240]推测应该是胰腺的CT值范围

数据增强：对3D CT立方体进行旋转和翻转，旋转$90\degree, 180\degree, 270\degree$，翻转为沿着三个轴翻转，通过不同的组合获得不同的训练数据，这样做可以增加数据的数量，提升网络的性能。

在粗分割的训练阶段，训练数据只包含一些非胰腺器官的体素和胰腺器官可以起到平衡像素值得作用；另外，减小非胰腺部分的大小还可以减少假阳性。

粗分割的测试阶段，设置滑动窗口的重叠参数为6，因为是粗分割，所以要保证速度，而设置重叠参数较小，可以有效的加速训练

在精细分割的训练阶段，限定ground truth只是胰腺的那部分区域，并在此进行训练

在精细分割的测试阶段，滑动窗口的训练重叠参数为12，因为本身训练数据尺寸不大，并且要获得精细的效果，就把重叠尺寸设置大一些。

## 评价指标
Dice-Sørensen Coefficient

## 可以采纳的地方
1. 数据初始化CT值截断
2. 数据扩充方法
3. 由粗到细的思想